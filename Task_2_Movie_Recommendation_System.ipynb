{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TASK-2:\n",
        "\n",
        "## **Movie Recommendation System :**\n",
        "**Build a movie recommendation system\n",
        "using collaborative filtering and machine\n",
        "learning techniques in Python.**"
      ],
      "metadata": {
        "id": "ZMEGYrsj3QZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMmVqt3mWDPR",
        "outputId": "6aea7d0d-f624-4b72-8df7-3acb804a00f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357255 sha256=58623de98cba6f5004aaebda9c68f953730a5043231754f74cce0ba69fd57535\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install kaggle\n",
        "!pip install surprise\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Move kaggle.json to the appropriate directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the MovieLens dataset\n",
        "!kaggle datasets download -d grouplens/movielens-20m-dataset\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip movielens-20m-dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "4IV-uZ5oWVU2",
        "outputId": "17d741e0-893c-4140-f61e-b9b6dd8719ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56f08b15-9815-4877-825c-736e89e9b3d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-56f08b15-9815-4877-825c-736e89e9b3d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset\n",
            "License(s): unknown\n",
            "Downloading movielens-20m-dataset.zip to /content\n",
            "100% 195M/195M [00:04<00:00, 45.3MB/s]\n",
            "100% 195M/195M [00:04<00:00, 43.0MB/s]\n",
            "Archive:  movielens-20m-dataset.zip\n",
            "  inflating: genome_scores.csv       \n",
            "  inflating: genome_tags.csv         \n",
            "  inflating: link.csv                \n",
            "  inflating: movie.csv               \n",
            "  inflating: rating.csv              \n",
            "  inflating: tag.csv                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "ratings = pd.read_csv('rating.csv')\n",
        "movies = pd.read_csv('movie.csv')\n",
        "\n",
        "# Display the first few rows of the datasets\n",
        "print(ratings.head())\n",
        "print(movies.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63kruqM7Wcwl",
        "outputId": "062a6c0e-476b-41d5-be38-a6207c495889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating            timestamp\n",
            "0       1        2     3.5  2005-04-02 23:53:47\n",
            "1       1       29     3.5  2005-04-02 23:31:16\n",
            "2       1       32     3.5  2005-04-02 23:33:39\n",
            "3       1       47     3.5  2005-04-02 23:32:07\n",
            "4       1       50     3.5  2005-04-02 23:29:40\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for Surprise library\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "x3jzqjRKWszO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train the SVD model\n",
        "model = SVD()\n",
        "model.fit(trainset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph6L7nOSXfOM",
        "outputId": "de757192-7224-44f8-e2d4-1bff1fe1166b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7b997c10f580>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Calculate RMSE\n",
        "pred_ratings = [pred.est for pred in predictions]\n",
        "true_ratings = [pred.r_ui for pred in predictions]\n",
        "rmse = mean_squared_error(true_ratings, pred_ratings, squared=False)\n",
        "print(f'RMSE: {rmse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkRls3mKXlAq",
        "outputId": "78189b0b-646c-4896-ddf4-a8e31cc1bee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.7863508967386441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get top N recommendations for a given user\n",
        "def get_top_n_recommendations(user_id, model, movies, n=10):\n",
        "    user_ratings = ratings[ratings['userId'] == user_id]\n",
        "    user_rated_movies = user_ratings['movieId'].tolist()\n",
        "    all_movie_ids = movies['movieId'].tolist()\n",
        "    unrated_movies = [m for m in all_movie_ids if m not in user_rated_movies]\n",
        "\n",
        "    predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies]\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "    top_n_predictions = predictions[:n]\n",
        "    top_n_movie_ids = [pred.iid for pred in top_n_predictions]\n",
        "    top_n_movie_titles = movies[movies['movieId'].isin(top_n_movie_ids)]['title'].tolist()\n",
        "\n",
        "    return top_n_movie_titles\n",
        "\n",
        "# Get top 10 recommendations for a user\n",
        "user_id = 1\n",
        "top_n_recommendations = get_top_n_recommendations(user_id, model, movies)\n",
        "print(f'Top 10 movie recommendations for user {user_id}:')\n",
        "for i, movie in enumerate(top_n_recommendations):\n",
        "    print(f'{i+1}. {movie}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0lFAf0RXtsq",
        "outputId": "2bcdbe52-15cf-4731-a228-65ca7113c55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 movie recommendations for user 1:\n",
            "1. Life Is Beautiful (La Vita è bella) (1997)\n",
            "2. Prime Suspect (1991)\n",
            "3. Phone Box, The (Cabina, La) (1972)\n",
            "4. Serenity (2005)\n",
            "5. Amazing Journey: The Story of The Who (2007)\n",
            "6. How to Train Your Dragon (2010)\n",
            "7. Very Potter Musical, A (2009)\n",
            "8. For the Birds (2000)\n",
            "9. Frozen Planet (2011)\n",
            "10. Interstellar (2014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Explanation:**"
      ],
      "metadata": {
        "id": "PIZu0jFjhAY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of the Code:\n",
        "The primary purpose of this code is to build a movie recommendation system using collaborative filtering and machine learning techniques in Python. Specifically, it utilizes the Singular Value Decomposition (SVD) algorithm from the Surprise library to recommend movies to users based on their past ratings.\n",
        "\n",
        "## Libraries and Frameworks Used\n",
        "1. **Pandas**: For data manipulation and analysis. It provides data structures like DataFrame to work with structured data.\n",
        "2. **NumPy:** A library for numerical computations in Python.\n",
        "3. **Surprise:** A Python scikit for building and analyzing recommender systems. It provides various ready-to-use algorithms, including SVD.\n",
        "4. **Scikit-learn:** A machine learning library in Python, used here for evaluating the model.\n",
        "5. **Matplotlib and Seaborn:** Libraries for data visualization.\n",
        "\n",
        "## Technologies Used\n",
        "1. **Collaborative Filtering:** A technique used by recommender systems to find similarities between users or items and provide recommendations.\n",
        "2. **Singular Value Decomposition (SVD):** A matrix factorization technique used in collaborative filtering to decompose the user-item interaction matrix into latent factors.\n",
        "3. **Kaggle API:** Used to download datasets directly from Kaggle.\n",
        "\n",
        "## Dataset Used\n",
        "The MovieLens 20M dataset from Kaggle is used in this project. This dataset contains 20 million ratings for 27,000 movies by 138,000 users. It is a popular dataset for building and benchmarking recommendation systems.\n",
        "\n",
        "## Step-by-Step Explanation\n",
        "**Step 1: Set Up Environment and Install Necessary Libraries**\n",
        "\n",
        "In this step, we install the required libraries using pip. The libraries include kaggle for downloading datasets, surprise for building recommendation models, and scikit-learn for evaluation metrics.\n",
        "\n",
        "**Code:**\n",
        "\n",
        "```\n",
        "!pip install kaggle\n",
        "!pip install surprise\n",
        "!pip install scikit-learn\n",
        "```\n",
        "\n",
        "\n",
        "We then import the necessary libraries for data handling, machine learning, and visualization.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "**Step 2: Configure Kaggle API and Download Dataset**\n",
        "\n",
        "We configure the Kaggle API to download the MovieLens dataset. You need to upload your Kaggle API key (kaggle.json) to the Colab environment. The key is used to authenticate and download datasets from Kaggle.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "```\n",
        "\n",
        "We then create a directory for the Kaggle key, move the uploaded file to this directory, and set the appropriate permissions.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "```\n",
        "\n",
        "Next, we download and unzip the MovieLens dataset.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "!kaggle datasets download -d grouplens/movielens-20m-dataset\n",
        "!unzip movielens-20m-dataset.zip\n",
        "```\n",
        "\n",
        "**Step 3: Load and Preprocess the Data**\n",
        "\n",
        "We load the ratings and movies data into Pandas DataFrames.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "ratings = pd.read_csv('rating.csv')\n",
        "movies = pd.read_csv('movie.csv')\n",
        "```\n",
        "Displaying the first few rows of these datasets helps to understand their structure.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "print(ratings.head())\n",
        "print(movies.head())\n",
        "```\n",
        "\n",
        "**Step 4: Prepare Data for Surprise Library**\n",
        "\n",
        "The Surprise library requires data in a specific format. We use the Reader class to define the rating scale and load the data from our DataFrame.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "reader = Reader(rating_scale=(0.5, 5.0))\n",
        "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "```\n",
        "\n",
        "We then split the data into training and testing sets using an 80-20 split.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "```\n",
        "\n",
        "**Step 5: Build and Train the SVD Model**\n",
        "\n",
        "We initialize the SVD model and train it using the training set.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "```\n",
        "\n",
        "**Step 6: Evaluate the Model**\n",
        "\n",
        "To evaluate the model, we make predictions on the test set and calculate the Root Mean Squared Error (RMSE) between the predicted and true ratings. RMSE is a common metric used to measure the accuracy of predicted ratings.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "predictions = model.test(testset)\n",
        "pred_ratings = [pred.est for pred in predictions]\n",
        "true_ratings = [pred.r_ui for pred in predictions]\n",
        "rmse = mean_squared_error(true_ratings, pred_ratings, squared=False)\n",
        "print(f'RMSE: {rmse}')\n",
        "```\n",
        "**Step 7: Generate Movie Recommendations**\n",
        "\n",
        "We define a function to generate the top N movie recommendations for a given user. The function identifies movies that the user has not rated yet, predicts ratings for these movies, and returns the top N movies with the highest predicted ratings.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "def get_top_n_recommendations(user_id, model, movies, n=10):\n",
        "    user_ratings = ratings[ratings['userId'] == user_id]\n",
        "    user_rated_movies = user_ratings['movieId'].tolist()\n",
        "    all_movie_ids = movies['movieId'].tolist()\n",
        "    unrated_movies = [m for m in all_movie_ids if m not in user_rated_movies]\n",
        "    \n",
        "    predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies]\n",
        "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    \n",
        "    top_n_predictions = predictions[:n]\n",
        "    top_n_movie_ids = [pred.iid for pred in top_n_predictions]\n",
        "    top_n_movie_titles = movies[movies['movieId'].isin(top_n_movie_ids)]['title'].tolist()\n",
        "    \n",
        "    return top_n_movie_titles\n",
        "```\n",
        "\n",
        "We can then use this function to get movie recommendations for a specific user.\n",
        "\n",
        "**Code:**\n",
        "```\n",
        "user_id = 1\n",
        "top_n_recommendations = get_top_n_recommendations(user_id, model, movies)\n",
        "print(f'Top 10 movie recommendations for user {user_id}:')\n",
        "for i, movie in enumerate(top_n_recommendations):\n",
        "    print(f'{i+1}. {movie}')\n",
        "```\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This project demonstrates how to build a movie recommendation system using collaborative filtering with the SVD algorithm. The code covers the entire pipeline from data loading and preprocessing to model training, evaluation, and generating recommendations. The MovieLens dataset is used for this purpose, and the Surprise library provides an efficient way to implement and evaluate the recommendation algorithms."
      ],
      "metadata": {
        "id": "lTVwMJ2TarbE"
      }
    }
  ]
}